\documentclass{article}

\usepackage{graphicx} % Required for the inclusion of images
\usepackage{natbib} % Required to change bibliography style to APA
\usepackage{amsmath} % Required for some math elements
\usepackage[final]{pdfpages}
\usepackage[parfill]{parskip}
\usepackage{bm}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{gensymb}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algpseudocode}


\usepackage{amsmath,amsfonts,amssymb}

\setlength\parindent{0pt} % Removes all indentation from paragraphs

\renewcommand{\labelenumi}{\alph{enumi}.} % Make numbering in the enumerate environment by letter rather than number (e.g. section 6)

%\usepackage{times} % Uncomment to use the Times New Roman font

%----------------------------------------------------------------------------------------
%	DOCUMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Comparison of action representations under function approximation \\ \large CS394R Fall 2016} % Title

\author{\textsc{Nick Walker}} % Author name

\date{\today} % Date for the report

\begin{document}

	\maketitle % Insert the title, author and date


	%----------------------------------------------------------------------------------------
	%	SECTION 1
	%----------------------------------------------------------------------------------------

	\section{Motivation}
	
	We have covered numerous extensions to the fundamental TD approach. I applied 



	%----------------------------------------------------------------------------------------
	%	SECTION 2
	%----------------------------------------------------------------------------------------

	\section{Introduction}

	\subsection{Problem}
	
	I chose the stochastic windy gridworld task presented in example 6.5 and subsequent exercises. In this environment, the agent can move in cardinal directions, but for portions of the grid a stochastic wind may push the agent above or below its movement target. The agent receives -1 reward at each time step, except for actions that transition to the goal, which yield +50.
	
			\begin{figure}[h]
				\begin{center}
					\includegraphics[width=\textwidth]{gridworld.png}
					\caption{.}
				\end{center}
			\end{figure}


	\subsection{Learning Approaches}

	\subsubsection{Tabular?}

	\subsubsection{Function Approximation}



	\begin{equation}\label{eqn:update}
	\bm{\theta}_{t+1} =
	\bm{\theta}_t +
	\alpha \Big[
		R_{t+1} +
		\gamma \hat{q}(S_{t+1}, A_{t+1}\, \bm{\theta}_t)
		- \hat{q}(S_t, A_t, \bm{\theta}_t)
	\Big]
	\Delta\hat{q}(S_t, A_t, \bm{\theta}_t)\tag{1}
	\end{equation}

	And in the linear case:

	\begin{equation}\label{eqn:linear_update}
		\bm{\theta}_{t+1} =
		\bm{\theta}_t +
			\alpha \Big[
				R_{t+1} + \gamma\, \bm{\theta}_t^\top\bm{\phi}_{t+1} \space
				- \bm{\theta}_t^\top\bm{\phi}_t
			\Big]\bm{\phi}_t\tag{2}
	\end{equation}


	%----------------------------------------------------------------------------------------
	%	SECTION 3
	%----------------------------------------------------------------------------------------


	\section{Experimental Setup}

	\subsection{Features}

	%----------------------------------------------------------------------------------------
	%	SECTION 4
	%----------------------------------------------------------------------------------------


	\section{Results}


		\begin{figure}[h]
			\begin{center}
				\includegraphics[width=\textwidth]{figure_0.pdf}
				\caption{.}
			\end{center}
		\end{figure}

	\subsection{Discussion}


	%----------------------------------------------------------------------------------------
	%	SECTION 5
	%----------------------------------------------------------------------------------------

	\section{Conclusions}


	\clearpage



\end{document}